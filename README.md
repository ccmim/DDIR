# DDIR
The source code of "A Deep Discontinuity-Preserving Image Registration Network", which is a deep learning-based image registration network, taking the discontinuity-preserving into consideration.

## Contents
- <a href="#Abstract">`Abstract`</a>
- <a href="#Network">`Network`</a>
- <a href="#Repo Contents">`Repo Contents`</a>
- <a href="#Package dependencies">`Package dependencies`</a>
- <a href="#Dataset">`Dataset`</a>
- <a href="#Training">`Training`</a>
- <a href="#Testing">`Testing`</a>
- <a href="#Demo">`Demo`</a>
- <a href="#Citation">`Citation`</a>

## Abstract:<a id="Abstract"/>
Image registration aims to establish spatial correspondence across pairs, or groups of images, and is a cornerstone of medical image computing and computer-assisted-interventions. Currently, most deep learning-based registration methods assume that the desired deformation fields are globally smooth and continuous, which is not always valid for real-world scenarios, especially in medical image registration (e.g. cardiac imaging and abdominal imaging). Such a global constraint can lead to artefacts and increased errors at discontinuous tissue interfaces. To tackle this issue, we propose a weakly-supervised Deep Discontinuity-preserving Image Registration network (DDIR), to obtain better registration performance and realistic deformation fields. We demonstrate that our method achieves significant improvements in registration accuracy and predicts more realistic deformations, in registration experiments on cardiac magnetic resonance (MR) images from UK Biobank Imaging Study (UKBB), than state-of-the-art approaches. 

## Network:<a id="Network"/>
The kernal idea is to use dep learning network to mimic the process of deforming the template mesh under the guidence of contours.
![image](https://github.com/XiangChen1994/MR-Net/blob/main/fig/MRNet.png)

## Repo Contents:<a id="Repo Contents"/>
This code is based on [Pixel2mesh](https://github.com/nywang16/Pixel2Mesh), where the GCN block and the mesh loss are mainly from it.
The point feature extraction is partially referred to [PointNet++](https://github.com/charlesq34/pointnet2).

## Package dependencies:<a id="Package dependencies"/>
This repository is based on Python2.7, Tensorflow and Tensorlayer.
The version of the main packages is as follows,
- Tensorflow==1.7.0
- tflearn

## Dataset:<a id="Dataset"/>
Our network is trained based on UKBB dataset. The input contours are extracted from manual segmentation results, and the groun-truth is generated by traditional method (deforming a template mesh conditioned by the corresponding contours). If you want to train MR-Net by yourself but have no access to the UKBB, ACDC dataset could be another option.

## Training:<a id="Training"/>
Use the following command to train the MR-Net.
```sh
 CUDA_VISIBLE_DEVICES=0 python train.py  --data_dir path/to/trainfile/
```

## Testing:<a id="Testing"/>
Use the following command to test the MR-Net. Chamfer Distance (CD), Earth Mover Distance (EMD), Hausdorff Distance (HD) and Point cloud to point cloud (PC-to-PC) error are evaluated in this paper.
```sh
CUDA_VISIBLE_DEVICES=0 python test.py --data_dir path/to/testfile/
```

## Demo:<a id="Demo"/>
To reconstruct 3D cardiac mesh with pretrained model from contours.
```sh
CUDA_VISIBLE_DEVICES=0 python demo.py --test_file demo/test.vtk
```

## Citation:<a id="Citation"/>
to do.
